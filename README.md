Asistente Conversacional Inteligente (RAG)

Este proyecto es el resultado del Curso de Desarrollo de Asistentes Conversacionales. El objetivo es construir un asistente que responda preguntas de manera precisa y eficiente utilizando Generaci√≥n Aumentada por Recuperaci√≥n (RAG), integrando tecnolog√≠as modernas para bases de datos vectoriales, memoria, y frameworks como Langchain o Langgraph.
üöÄ Objetivo del Proyecto
Desarrollo de un asistente conversacional que pueda:
‚Ä¢	Responder preguntas sobre una base de conocimientos espec√≠fica.
‚Ä¢	Mantener una conversaci√≥n fluida gracias a su sistema de memoria.
üõ†Ô∏è Componentes T√©cnicos
1. Generaci√≥n Aumentada por Recuperaci√≥n (RAG)
El asistente utiliza una base de datos vectorial para manejar su fuente de conocimiento. Esto permite responder preguntas que no est√°n directamente cubiertas por los datos de entrenamiento del modelo base.
Bases de datos vectoriales :
‚Ä¢	FAISS
2. Framework
La soluci√≥n se construye utilizando:
‚Ä¢	Langchain  para la implementaci√≥n y orquestaci√≥n del asistente.
3. Memoria
‚Ä¢	Memoria conversacional para continuar interacciones de manera coherente.
4. Interfaz de Usuario
El asistente est√° dise√±ado para ser utilizado a trav√©s de:
‚Ä¢	Streamlit (implementaci√≥n principal)

5. Modelo
 llm = ChatGroq(model="llama-3.2-90b-vision-preview")
  embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

üìã Requisitos de Instalaci√≥n
1. Clonar el Repositorio
git clone https://github.com/ClauAcosta/proyecto-chatbot-ia.git
2. Instalar Dependencias
pip install -r requirements.txt
3. Configuraci√≥n
‚Ä¢	Proporciona las credenciales necesarias para acceso a la base de datos vectorial y API de internet.
‚Ä¢	Configura las variables de entorno en un archivo .env.
üñ•Ô∏è Uso
1.	Inicia la aplicaci√≥n:
streamlit run app_st_chatbot.py
2.	Accede a la interfaz en http://localhost:8501.
3.	Realiza preguntas o explora las funcionalidades del asistente.

